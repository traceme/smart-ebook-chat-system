version: '3.8'

services:
  backend:
    build:
      context: .
      dockerfile: Dockerfile
    env_file:
      - env.prod
    environment:
      - ENVIRONMENT=production
      - DEBUG=false
      - LOG_LEVEL=warning
    depends_on:
      - db
      - redis
      - qdrant
      - minio
    networks:
      - app-network
    restart: always
    deploy:
      replicas: 3
      update_config:
        parallelism: 1
        delay: 10s
        failure_action: rollback
        order: start-first
      rollback_config:
        parallelism: 1
        delay: 5s
        failure_action: pause
        order: stop-first
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
        window: 120s
      resources:
        limits:
          cpus: '2.0'
          memory: 2G
        reservations:
          cpus: '1.0'
          memory: 1G
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "5"
        labels: "service=backend,environment=production"

  frontend:
    build:
      context: ../my-gatsby-site
      dockerfile: Dockerfile.simple
    environment:
      - NODE_ENV=production
    networks:
      - app-network
    restart: always
    deploy:
      replicas: 2
      update_config:
        parallelism: 1
        delay: 10s
        failure_action: rollback
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
        window: 120s
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "5"
        labels: "service=frontend,environment=production"

  celery-worker:
    build:
      context: .
      dockerfile: Dockerfile
    env_file:
      - env.prod
    environment:
      - ENVIRONMENT=production
      - DEBUG=false
      - LOG_LEVEL=warning
    depends_on:
      - db
      - redis
      - minio
    command: ["celery", "-A", "app.workers.celery_app", "worker", "--loglevel=warning", "--concurrency=8", "-Q", "document_conversion,vector_indexing,celery", "--max-tasks-per-child=1000"]
    networks:
      - app-network
    restart: always
    deploy:
      replicas: 2
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
        window: 120s
      resources:
        limits:
          cpus: '4.0'
          memory: 4G
        reservations:
          cpus: '2.0'
          memory: 2G
    healthcheck:
      test: ["CMD", "celery", "-A", "app.workers.celery_app", "inspect", "ping"]
      interval: 60s
      timeout: 10s
      retries: 3
      start_period: 60s
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "5"
        labels: "service=celery-worker,environment=production"

  celery-beat:
    build:
      context: .
      dockerfile: Dockerfile
    env_file:
      - env.prod
    environment:
      - ENVIRONMENT=production
      - DEBUG=false
      - LOG_LEVEL=warning
    depends_on:
      - redis
    command: ["celery", "-A", "app.workers.celery_app", "beat", "--loglevel=warning", "--pidfile=/tmp/celerybeat.pid"]
    networks:
      - app-network
    restart: always
    deploy:
      replicas: 1
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
        window: 120s
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 256M
    volumes:
      - celery_beat_schedule:/app/schedule
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "5"
        labels: "service=celery-beat,environment=production"

  db:
    image: postgres:13
    volumes:
      - postgres_prod_data:/var/lib/postgresql/data/
      - ./backups:/backups
      - ./postgresql.conf:/etc/postgresql/postgresql.conf:ro
    environment:
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - POSTGRES_DB=${POSTGRES_DB}
      - POSTGRES_INITDB_ARGS=--auth-host=md5
    command: postgres -c config_file=/etc/postgresql/postgresql.conf
    networks:
      - app-network
    restart: always
    deploy:
      replicas: 1
      restart_policy:
        condition: on-failure
        delay: 10s
        max_attempts: 5
        window: 300s
      resources:
        limits:
          cpus: '2.0'
          memory: 4G
        reservations:
          cpus: '1.0'
          memory: 2G
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER} -d ${POSTGRES_DB}"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    logging:
      driver: "json-file"
      options:
        max-size: "100m"
        max-file: "10"
        labels: "service=database,environment=production"

  redis:
    image: redis:6.2-alpine
    volumes:
      - redis_prod_data:/data
      - ./redis-prod.conf:/usr/local/etc/redis/redis.conf:ro
    command: redis-server /usr/local/etc/redis/redis.conf
    networks:
      - app-network
    restart: always
    deploy:
      replicas: 1
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 5
        window: 300s
      resources:
        limits:
          cpus: '1.0'
          memory: 2G
        reservations:
          cpus: '0.5'
          memory: 1G
    healthcheck:
      test: ["CMD", "redis-cli", "--no-auth-warning", "ping"]
      interval: 30s
      timeout: 5s
      retries: 5
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "5"
        labels: "service=redis,environment=production"

  qdrant:
    image: qdrant/qdrant:v1.8.0
    volumes:
      - qdrant_prod_storage:/qdrant/storage
      - ./qdrant-prod-config.yaml:/qdrant/config/production.yaml:ro
    environment:
      - QDRANT__SERVICE__HTTP_PORT=6333
      - QDRANT__LOG_LEVEL=WARN
      - QDRANT__SERVICE__ENABLE_CORS=false
    networks:
      - app-network
    restart: always
    deploy:
      replicas: 1
      restart_policy:
        condition: on-failure
        delay: 10s
        max_attempts: 5
        window: 300s
      resources:
        limits:
          cpus: '2.0'
          memory: 4G
        reservations:
          cpus: '1.0'
          memory: 2G
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:6333/health"]
      interval: 30s
      timeout: 10s
      retries: 5
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "5"
        labels: "service=qdrant,environment=production"

  minio:
    image: minio/minio:RELEASE.2023-03-20T20-16-18Z
    volumes:
      - minio_prod_storage:/data
    environment:
      - MINIO_ROOT_USER=${MINIO_ROOT_USER}
      - MINIO_ROOT_PASSWORD=${MINIO_ROOT_PASSWORD}
      - MINIO_BROWSER_REDIRECT_URL=${MINIO_BROWSER_URL}
      - MINIO_SERVER_URL=${MINIO_SERVER_URL}
    command: server /data --console-address ":9001"
    networks:
      - app-network
    restart: always
    deploy:
      replicas: 1
      restart_policy:
        condition: on-failure
        delay: 10s
        max_attempts: 5
        window: 300s
      resources:
        limits:
          cpus: '1.0'
          memory: 2G
        reservations:
          cpus: '0.5'
          memory: 1G
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 10s
      retries: 5
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "5"
        labels: "service=minio,environment=production"

  # Production load balancer with SSL
  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/prod.conf:/etc/nginx/nginx.conf:ro
      - ./ssl:/etc/nginx/ssl:ro
      - nginx_cache:/var/cache/nginx
      - certbot_prod_data:/var/www/certbot
    depends_on:
      - backend
      - frontend
    networks:
      - app-network
    restart: always
    deploy:
      replicas: 2
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
        window: 120s
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    logging:
      driver: "json-file"
      options:
        max-size: "100m"
        max-file: "10"
        labels: "service=nginx,environment=production"

  certbot:
    image: certbot/certbot
    volumes:
      - certbot_prod_data:/var/www/certbot
      - ./ssl:/etc/letsencrypt
    entrypoint: "/bin/sh -c 'trap exit TERM; while :; do certbot renew --quiet; sleep 12h & wait $${!}; done;'"
    networks:
      - app-network
    restart: always
    deploy:
      restart_policy:
        condition: on-failure
        delay: 60s
        max_attempts: 3
        window: 86400s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
        labels: "service=certbot,environment=production"

  # Production monitoring (minimal)
  node-exporter:
    image: prom/node-exporter:latest
    command:
      - '--path.procfs=/host/proc'
      - '--path.rootfs=/rootfs'
      - '--path.sysfs=/host/sys'
      - '--collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc)($$|/)'
    volumes:
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /:/rootfs:ro
    networks:
      - app-network
    restart: always
    deploy:
      mode: global
      resources:
        limits:
          cpus: '0.1'
          memory: 128M

  cadvisor:
    image: gcr.io/cadvisor/cadvisor:latest
    volumes:
      - /:/rootfs:ro
      - /var/run:/var/run:ro
      - /sys:/sys:ro
      - /var/lib/docker/:/var/lib/docker:ro
      - /dev/disk/:/dev/disk:ro
    privileged: true
    devices:
      - /dev/kmsg
    networks:
      - app-network
    restart: always
    deploy:
      mode: global
      resources:
        limits:
          cpus: '0.2'
          memory: 256M

volumes:
  postgres_prod_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: /opt/app/data/postgres
  redis_prod_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: /opt/app/data/redis
  qdrant_prod_storage:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: /opt/app/data/qdrant
  minio_prod_storage:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: /opt/app/data/minio
  nginx_cache:
  certbot_prod_data:
  celery_beat_schedule:

networks:
  app-network:
    driver: overlay
    attachable: false
    ipam:
      config:
        - subnet: 172.30.0.0/16
    driver_opts:
      encrypted: "true" 